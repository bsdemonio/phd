#!/usr/bin/python
import glob;
import pyPdf;
import subprocess;
import os;
import time;
from collections import Counter;
import re;
import MySQLdb;
import json
class ExtractData:
   def __init__(self, directory):
      self.directory = directory;
   
   def getFiles(self):
     from os import listdir;
     from os.path import isfile, join;
     onlyfiles = [ f for f in listdir(self.directory) if isfile(join(self.directory,f)) ];
     return onlyfiles;
   
   def insertDB(self,tabArray,tablename):
      tablename = tablename.replace('.pdf','');
      #print(tablename);
      db = MySQLdb.connect(host="localhost",user="root",passwd="",db="phd");
      cur = db.cursor();
      sql =('DROP TABLE IF EXISTS tab'+tablename)
      cur.execute(sql)
      message_table = "CREATE TABLE tab"+tablename+" (iddb INTEGER AUTO_INCREMENT PRIMARY KEY,word VARCHAR(50) DEFAULT NULL,number float);";
      #print (message_table);
      cur.execute(message_table);
      for info in tabArray:
         val1=info[0];
         val2=info[1];
         cur.execute('insert into tab'+tablename+'(word,number) values (%s,%s)',(val1,val2));

      db.commit(); 
      #db.commit();
      #cur.execute("TRUNCATE TABLE "+tablename);
      #db.commit();
   
   def insertDBAuto(self,tabArray):
      db = MySQLdb.connect(host="localhost",user="root",passwd="",db="phd");
      cur = db.cursor();
      for element in tabArray:             
         sql=('select id from phdData where word like "'+element[0]+'"');
         cur.execute(sql);
         rows = cur.fetchall()
         existingID=0;
         if (len(rows) > 0):
            existingID= rows[0][0]; 
         if (existingID == 0):
            cur.execute('insert into phdData (word,container) values (%s,%s)',(element[0],element[1]));
         else:
            sql=('select container from phdData where word like "'+element[0]+'"');
            cur.execute(sql);
            rows = cur.fetchall()
            papersRelated = rows[0][0].split('|');
            if element[1] not in papersRelated:
               papersRelated.append(element[1])
            #print(papersRelated);
            #print("|".join(str(x) for x in papersRelated));
            newContainer = '|'.join(map(str, papersRelated))
            sql=('update phdData set container = "'+newContainer+'" where word like "'+element[0]+'"');
            cur.execute(sql);
            
      db.commit(); 
      #db.commit();
      #cur.execute("TRUNCATE TABLE "+tablename);
      #db.commit();

   def readPDF(self,files):
      from StringIO import StringIO;
      for name in files:
         validateContent = "";
         route = '/Users/Alan/Documents/python/phd/pdfminer-20140328/tools/pdf2txt.py';
         #sp_args = ['python', route, '-p', '1', '-o', 'outtemp/'+name+'.out', self.directory + '/' + name];
         sp_args = ['python', route,  '-o', 'outtemp/'+name+'.out', self.directory + '/' + name];
         sp = subprocess.Popen(sp_args);
         time.sleep(3);
         ins = open( 'outtemp/'+name+'.out', "r" );
         array = [];
         for line in ins:
             array.append( line );
         ins.close(); 
         cont =0;
         if (len(array) > 2):
            unique = [];
            fullPaper = [];
            for line in array:
               split = line.split( );
               for element in split:
                  stringWithNumbers = element;
                  stringWithoutNumbers=''.join(c if c not in map(str,range(0,10)) else "" for c in stringWithNumbers);
                  element = stringWithoutNumbers;
                  re.sub(r'[^\w]', ' ', element);
                  punctuations = '''!()-[]{};:'"\,<>./?@#$%^&*_~''';
                  no_punct = "";
                  my_str = element;
                  for char in my_str:
                     if char not in punctuations:
                        no_punct = no_punct + char
                  element = no_punct.lower();
                  if len(element) > 3:
                     fullPaper.append(element);
                     if element in unique:
                        cont=cont +1;
                     else:
                        unique.append(element);
            #print len(fullPaper);
            print len(unique);
            average = [];
            data = [];
            fullPaperwithcount = Counter(fullPaper);
            #print(fullPaperwithcount);
            mostbig = 0;
            for element in unique:
               avtemp = fullPaperwithcount[element];
               average.append([element,avtemp]);
               if avtemp in data:
                  mostbig=mostbig+1;
               else:
                  data.append(avtemp);
            print(sorted(data));
            dOrder=sorted(data)

            n=len(dOrder)
            middle=n/2
            # codigo para calcular la media aritmetica
            print 'Mediana Aritmetica: ', round(sum(data)*1.0/n,2)

            mediaAritmetica =  round(sum(data)*1.0/n,2);

            # codigo para calcular la mediana
            if n%2==0:
               mediana=(dOrder[middle+1] + dOrder[middle+2]) / 2
            else:
               mediana=dOrder[middle+1]*1

            print ''
            print 'Total datos', n
            print 'Mediana: ', mediana
            print len(average); 

            finalAverage = [];
            blacklist=['this','their','with','that','using','references','exercises','using','which','chapter','september'];
            for element in average:             
               if(element[1]/mediaAritmetica > .5 and element[0] not in blacklist): 
                  finalAverage.append([element[0],(element[1]/mediaAritmetica)]);
            
            processedInfo = [];
            for element in finalAverage:             
               processedInfo.append([element[0],name]);
            
            #self.insertDB(average,name); line to insert stuff in database not necessary now ... it would change
            print(finalAverage);
            print json.dumps(processedInfo);
            self.insertDBAuto(processedInfo)
            print '---------------------------------';
         del array[:]
         del unique[:]
         #os.remove(path);
         #time.sleep(5)

data = ExtractData("development");
files = data.getFiles();
#print len(files)
data.readPDF(files);
